{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNecEDpUMhkRw5c+9sH2Au",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanu-N-Prabhu/Python/blob/master/Machine%20Learning%20Interview%20Prep%20Questions/Supervised%20Learning%20Algorithms/Ensemble%20Learning/ensemble_learning_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Learning from Scratch (No ML Libraries)\n",
        "\n",
        "In this notebook, you'll learn:\n",
        "\n",
        "- What ensemble learning is and why it works\n",
        "- Key types: Bagging, Boosting, and Stacking\n",
        "- How to implement **Bagging (Random Forest)** and **Boosting (AdaBoost)** using NumPy\n",
        "\n",
        "\n",
        "## What is Ensemble Learning?\n",
        "\n",
        "Ensemble learning combines predictions from **multiple models** (often weak learners) to create a **stronger** final model.\n",
        "\n",
        "### Three Common Types:\n",
        "- **Bagging**: Train models independently on random subsets (e.g., Random Forest)\n",
        "- **Boosting**: Train models sequentially, focusing on mistakes (e.g., AdaBoost)\n",
        "- **Stacking**: Combine outputs of base models using a meta-model\n",
        "\n",
        "Why it works:\n",
        "- Reduces overfitting (variance)\n",
        "- Improves accuracy\n",
        "- Increases robustness\n",
        "\n",
        "\n",
        "## Dataset\n",
        "We'll use a simple 1D classification task for illustration:\n"
      ],
      "metadata": {
        "id": "ghh_ioQwfV7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate synthetic 1D binary classification data\n",
        "np.random.seed(42)\n",
        "X = np.linspace(0, 10, 100).reshape(-1, 1)\n",
        "y = (X[:, 0] > 5).astype(int)\n",
        "y[:20] = 1  # Add noise\n",
        "y[-20:] = 0"
      ],
      "metadata": {
        "id": "Nn8BXBfIffIS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvbhSFkNfhPe",
        "outputId": "0a047db9-b9ef-43cf-a096-c56c95a7ce04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.        ]\n",
            " [ 0.1010101 ]\n",
            " [ 0.2020202 ]\n",
            " [ 0.3030303 ]\n",
            " [ 0.4040404 ]\n",
            " [ 0.50505051]\n",
            " [ 0.60606061]\n",
            " [ 0.70707071]\n",
            " [ 0.80808081]\n",
            " [ 0.90909091]\n",
            " [ 1.01010101]\n",
            " [ 1.11111111]\n",
            " [ 1.21212121]\n",
            " [ 1.31313131]\n",
            " [ 1.41414141]\n",
            " [ 1.51515152]\n",
            " [ 1.61616162]\n",
            " [ 1.71717172]\n",
            " [ 1.81818182]\n",
            " [ 1.91919192]\n",
            " [ 2.02020202]\n",
            " [ 2.12121212]\n",
            " [ 2.22222222]\n",
            " [ 2.32323232]\n",
            " [ 2.42424242]\n",
            " [ 2.52525253]\n",
            " [ 2.62626263]\n",
            " [ 2.72727273]\n",
            " [ 2.82828283]\n",
            " [ 2.92929293]\n",
            " [ 3.03030303]\n",
            " [ 3.13131313]\n",
            " [ 3.23232323]\n",
            " [ 3.33333333]\n",
            " [ 3.43434343]\n",
            " [ 3.53535354]\n",
            " [ 3.63636364]\n",
            " [ 3.73737374]\n",
            " [ 3.83838384]\n",
            " [ 3.93939394]\n",
            " [ 4.04040404]\n",
            " [ 4.14141414]\n",
            " [ 4.24242424]\n",
            " [ 4.34343434]\n",
            " [ 4.44444444]\n",
            " [ 4.54545455]\n",
            " [ 4.64646465]\n",
            " [ 4.74747475]\n",
            " [ 4.84848485]\n",
            " [ 4.94949495]\n",
            " [ 5.05050505]\n",
            " [ 5.15151515]\n",
            " [ 5.25252525]\n",
            " [ 5.35353535]\n",
            " [ 5.45454545]\n",
            " [ 5.55555556]\n",
            " [ 5.65656566]\n",
            " [ 5.75757576]\n",
            " [ 5.85858586]\n",
            " [ 5.95959596]\n",
            " [ 6.06060606]\n",
            " [ 6.16161616]\n",
            " [ 6.26262626]\n",
            " [ 6.36363636]\n",
            " [ 6.46464646]\n",
            " [ 6.56565657]\n",
            " [ 6.66666667]\n",
            " [ 6.76767677]\n",
            " [ 6.86868687]\n",
            " [ 6.96969697]\n",
            " [ 7.07070707]\n",
            " [ 7.17171717]\n",
            " [ 7.27272727]\n",
            " [ 7.37373737]\n",
            " [ 7.47474747]\n",
            " [ 7.57575758]\n",
            " [ 7.67676768]\n",
            " [ 7.77777778]\n",
            " [ 7.87878788]\n",
            " [ 7.97979798]\n",
            " [ 8.08080808]\n",
            " [ 8.18181818]\n",
            " [ 8.28282828]\n",
            " [ 8.38383838]\n",
            " [ 8.48484848]\n",
            " [ 8.58585859]\n",
            " [ 8.68686869]\n",
            " [ 8.78787879]\n",
            " [ 8.88888889]\n",
            " [ 8.98989899]\n",
            " [ 9.09090909]\n",
            " [ 9.19191919]\n",
            " [ 9.29292929]\n",
            " [ 9.39393939]\n",
            " [ 9.49494949]\n",
            " [ 9.5959596 ]\n",
            " [ 9.6969697 ]\n",
            " [ 9.7979798 ]\n",
            " [ 9.8989899 ]\n",
            " [10.        ]]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagging Example: Random Forest (Simplified)\n",
        "We'll simulate a Random Forest using multiple shallow decision stumps:"
      ],
      "metadata": {
        "id": "WBBX976GfmCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stump_predict(X, threshold):\n",
        "    return (X[:, 0] > threshold).astype(int)\n",
        "\n",
        "def bagging_predict(X, thresholds):\n",
        "    predictions = []\n",
        "    for t in thresholds:\n",
        "        pred = stump_predict(X, t)\n",
        "        predictions.append(pred)\n",
        "    return np.round(np.mean(predictions, axis=0)).astype(int)\n",
        "\n",
        "# Create a forest of 5 random decision stumps\n",
        "np.random.seed(0)\n",
        "thresholds = np.random.uniform(2, 8, size=5)\n",
        "y_pred_bag = bagging_predict(X, thresholds)\n",
        "\n",
        "accuracy_bag = np.mean(y_pred_bag == y)\n",
        "print(f\"Bagging Accuracy: {accuracy_bag:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QmE7vNjfnMf",
        "outputId": "d034d4e4-2981-4fd1-fb7d-6909b8852766"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boosting Example: AdaBoost with Decision Stumps"
      ],
      "metadata": {
        "id": "wCZ4xnw6ftVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adaboost(X, y, num_rounds=5):\n",
        "    n = X.shape[0]\n",
        "    weights = np.ones(n) / n\n",
        "    stumps = []\n",
        "    alphas = []\n",
        "\n",
        "    for _ in range(num_rounds):\n",
        "        best_error = float('inf')\n",
        "        best_threshold = None\n",
        "        best_pred = None\n",
        "\n",
        "        for t in np.linspace(0, 10, 100):\n",
        "            pred = stump_predict(X, t)\n",
        "            error = np.sum(weights * (pred != y))\n",
        "            if error < best_error:\n",
        "                best_error = error\n",
        "                best_threshold = t\n",
        "                best_pred = pred\n",
        "\n",
        "        alpha = 0.5 * np.log((1 - best_error + 1e-10) / (best_error + 1e-10))\n",
        "        weights *= np.exp(-alpha * y * (2 * best_pred - 1))\n",
        "        weights /= np.sum(weights)\n",
        "\n",
        "        stumps.append(best_threshold)\n",
        "        alphas.append(alpha)\n",
        "\n",
        "    return stumps, alphas\n",
        "\n",
        "def adaboost_predict(X, stumps, alphas):\n",
        "    pred_sum = np.zeros(X.shape[0])\n",
        "    for t, a in zip(stumps, alphas):\n",
        "        pred = stump_predict(X, t)\n",
        "        pred = 2 * pred - 1  # Convert {0,1} to {-1,1}\n",
        "        pred_sum += a * pred\n",
        "    return (pred_sum > 0).astype(int)\n",
        "\n",
        "# Train and predict\n",
        "stumps, alphas = adaboost(X, y, num_rounds=5)\n",
        "y_pred_boost = adaboost_predict(X, stumps, alphas)\n",
        "\n",
        "accuracy_boost = np.mean(y_pred_boost == y)\n",
        "print(f\"AdaBoost Accuracy: {accuracy_boost:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0fVBMWcfuC4",
        "outputId": "0591ab3e-ba03-4e67-daad-8f6094ac89a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Accuracy: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "- Learned what ensemble learning is\n",
        "- Implemented **Bagging** using random thresholds (Random Forest idea)\n",
        "- Implemented **Boosting** using AdaBoost and decision stumps\n",
        "- Used only NumPy and basic functions — no ML libraries\n",
        "\n",
        "This notebook builds strong intuition for how real ensemble algorithms like Random Forest and Gradient Boosting work.\n"
      ],
      "metadata": {
        "id": "3XMRLlJcfxmJ"
      }
    }
  ]
}